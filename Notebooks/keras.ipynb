{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import GlobalMaxPool1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = pd.read_csv('..\\Datasets\\Emotion_final.csv')\n",
    "dataset_2 = pd.read_csv('..\\Datasets\\Text_emotion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Emotion', ylabel='count'>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(x='Emotion', data=dataset_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    #Remove punctuation and numbers\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    #Single Character removal\n",
    "    text = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', text)\n",
    "\n",
    "    #Removing multiple spaces\n",
    "    text = re.sub(r\"\\s+\", ' ', text)\n",
    "    text = text.lower()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset_1, test_size= 0.3, random_state=111)\n",
    "train, val = train_test_split(train, test_size=0.3, random_state=111)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.Text\n",
    "X_test = test.Text\n",
    "X_val = val.Text\n",
    "\n",
    "y_train = train.Emotion\n",
    "y_test = test.Emotion\n",
    "y_val = val.Emotion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = list(class_weight.compute_class_weight(\n",
    "    class_weight = 'balanced', \n",
    "    classes = np.unique(dataset_1['Emotion']), \n",
    "    y = dataset_1['Emotion']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sadness', 'anger', 'love', 'surprise', 'fear', 'happy'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_1.Emotion.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5088206003698962,\n",
       " 0.5708699122106944,\n",
       " 1.194954894754427,\n",
       " 1.348604826546003,\n",
       " 2.179463741620963,\n",
       " 4.068828213879408]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {}\n",
    "\n",
    "for index, weight in enumerate(class_weights):\n",
    "    weights[index] = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5088206003698962,\n",
       " 1: 0.5708699122106944,\n",
       " 2: 1.194954894754427,\n",
       " 3: 1.348604826546003,\n",
       " 4: 2.179463741620963,\n",
       " 5: 4.068828213879408}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = tf.data.Dataset.from_tensor_slices((train['Text'].values, train['Emotion'].values))\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((test['Text'].values, test['Emotion'].values))\n",
    "dataset_val = tf.data.Dataset.from_tensor_slices((val['Text'].values, val['Emotion'].values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: b'i still very much feel submissive', Emotion: b'sadness'\n",
      "Text: b'im inclined to think his feeling disturbed is at least partly due to the manifest problems with the tactic', Emotion: b'sadness'\n",
      "Text: b'i feel guilty a little and also mildly worried but not bad enough to actually pursue anything', Emotion: b'sadness'\n",
      "Text: b'i feel like the dust in me has been shaken and still has not settled', Emotion: b'fear'\n",
      "Text: b'im not feeling very graceful today', Emotion: b'happy'\n"
     ]
    }
   ],
   "source": [
    "for text, target in dataset_train.take(5):\n",
    "    print(f'Text: {text}, Emotion: {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = tf.lookup.StaticHashTable(\n",
    "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
    "        keys=tf.constant(['sadness', 'anger', 'love', 'surprise', 'fear', 'happy']),\n",
    "        values=tf.constant([0,1,2,3,4,5]),\n",
    "    ),\n",
    "    default_value=tf.constant(-1),\n",
    "    name = \"target_encoding\"\n",
    ")\n",
    "\n",
    "@tf.function\n",
    "def target(x):\n",
    "    return table.lookup(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(dataset, size=5):\n",
    "    for batch, label in dataset.take(size):\n",
    "        print(batch.numpy())\n",
    "        print(target(label).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'im just feeling whiney'\n",
      "0\n",
      "b'It was Blackberry who bullied the stupefied Pipkin to his feet and forced him to limp the few yards to the grave'\n",
      "3\n",
      "b'i am standing so close to said cow her name is gabriella btw i feel rude calling her a cow'\n",
      "1\n",
      "b'i look flaky or streaky please feel free to tell me'\n",
      "5\n",
      "b'i feel like i was assaulted by a titanium hedgehog'\n",
      "4\n",
      "b'i feel anything for relationships the doomed one'\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "show_batch(dataset_test, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch(text, labels):\n",
    "    return text, tf.one_hot(target(labels), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_f = dataset_train.map(fetch)\n",
    "test_data_f = dataset_test.map(fetch)\n",
    "val_data_f = dataset_val.map(fetch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=string, numpy=b'i still very much feel submissive'>,\n",
       " <tf.Tensor: shape=(6,), dtype=float32, numpy=array([1., 0., 0., 0., 0., 0.], dtype=float32)>)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_data_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(5,), dtype=string, numpy=\n",
       " array([b'i still very much feel submissive',\n",
       "        b'im inclined to think his feeling disturbed is at least partly due to the manifest problems with the tactic',\n",
       "        b'i feel guilty a little and also mildly worried but not bad enough to actually pursue anything',\n",
       "        b'i feel like the dust in me has been shaken and still has not settled',\n",
       "        b'im not feeling very graceful today'], dtype=object)>,\n",
       " <tf.Tensor: shape=(5, 6), dtype=float32, numpy=\n",
       " array([[1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.]], dtype=float32)>)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, train_labels = next(iter(train_data_f.batch(5)))\n",
    "train_data, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 128), dtype=float32, numpy=\n",
       "array([[ 2.59699106e-01,  3.80535377e-03,  1.15070976e-01,\n",
       "         2.20660448e-01,  5.86057827e-02, -7.05655515e-02,\n",
       "         2.86433436e-02, -1.34522036e-01, -4.81358320e-02,\n",
       "        -1.07280444e-02,  1.38860181e-01, -1.34751588e-01,\n",
       "        -7.35047832e-02, -1.37675643e-01, -6.30882084e-02,\n",
       "         1.52496338e-01,  4.78207320e-02, -5.47323041e-02,\n",
       "        -1.27302408e-01,  3.93812023e-02,  1.55977115e-01,\n",
       "        -7.36882538e-02, -9.56825446e-03, -7.30612949e-02,\n",
       "         4.50265110e-02, -5.08982055e-02,  2.69979298e-01,\n",
       "         2.19272356e-02, -2.72957738e-02, -5.15200151e-03,\n",
       "         1.10490352e-01,  8.42242390e-02,  1.48596251e-02,\n",
       "         6.01801164e-02,  1.60738319e-01,  8.69318098e-02,\n",
       "        -1.97651550e-01, -1.27742842e-01,  1.03010565e-01,\n",
       "         1.95083469e-01, -2.37989724e-01, -3.49473357e-02,\n",
       "        -1.40261024e-01,  1.12089226e-02,  4.71913293e-02,\n",
       "         4.78265584e-02, -6.86534122e-02,  3.36280875e-02,\n",
       "        -2.09392488e-01,  1.30355526e-02,  4.70604636e-02,\n",
       "         3.11510805e-02, -9.47170407e-02,  1.59843311e-01,\n",
       "        -5.19882664e-02, -9.28505287e-02, -2.07649231e-01,\n",
       "        -6.52990490e-03, -1.30559728e-01,  1.72241367e-02,\n",
       "        -1.40996262e-01,  1.04102552e-01,  1.13796934e-01,\n",
       "         6.59160763e-02,  4.74629551e-02, -3.96988466e-02,\n",
       "        -2.98146289e-02, -9.54474211e-02,  1.64753929e-01,\n",
       "         8.56947806e-03, -1.17536552e-01,  5.11251800e-02,\n",
       "         3.71132120e-02, -9.41944271e-02,  3.02161481e-02,\n",
       "         6.61473200e-02,  4.20574033e-05, -1.77907228e-01,\n",
       "         4.71719615e-02, -2.97900122e-02, -1.15984976e-01,\n",
       "        -2.89409957e-03,  1.40417084e-01, -9.76427197e-02,\n",
       "         1.48471177e-01,  2.43999064e-02, -1.65041357e-01,\n",
       "         7.16401339e-02,  3.09347123e-01,  1.52881861e-01,\n",
       "         1.89957593e-03,  6.99136630e-02, -6.53473288e-02,\n",
       "        -7.72149116e-02, -2.04207879e-02,  5.05901165e-02,\n",
       "         9.26195458e-02, -2.83876210e-02, -7.24656284e-02,\n",
       "        -6.80575147e-02,  5.05900010e-03,  1.19446211e-01,\n",
       "         1.72796667e-01, -2.39287899e-03,  1.02654368e-01,\n",
       "        -1.15940601e-01, -2.45835893e-02, -3.83159448e-03,\n",
       "        -9.97425765e-02, -3.12848724e-02, -2.23893344e-01,\n",
       "        -2.11290881e-01, -6.67493418e-02, -4.40112762e-02,\n",
       "         1.92369763e-02, -6.55653998e-02,  9.38284025e-02,\n",
       "        -9.63968262e-02, -1.11141756e-01, -4.46026139e-02,\n",
       "         3.05957556e-01,  9.36221033e-02,  3.61392274e-02,\n",
       "         9.59973484e-02, -6.15488961e-02, -9.23380852e-02,\n",
       "        -1.98077902e-01,  1.37570485e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "embedding = \"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\"\n",
    "hub_layer = hub.KerasLayer(embedding, output_shape=[128], input_shape=[], dtype=tf.string, trainable=True)\n",
    "\n",
    "hub_layer(train_data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer_3 (KerasLayer)  (None, 128)               124642688 \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 6)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 124,686,246\n",
      "Trainable params: 124,686,246\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "for units in [128,128,64,32]:\n",
    "    model.add(tf.keras.layers.Dense(units, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(6, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer_3 (KerasLayer)  (None, 128)               124642688 \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 13)                429       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 124,686,477\n",
      "Trainable params: 124,686,477\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = tf.keras.Sequential()\n",
    "model2.add(hub_layer)\n",
    "for units in [128,128,64,32]:\n",
    "    model2.add(tf.keras.layers.Dense(units, activation='relu'))\n",
    "    model2.add(tf.keras.layers.Dropout(0.3))\n",
    "model2.add(tf.keras.layers.Dense(13, activation='softmax'))\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer_3 (KerasLayer)  (None, 128)               124642688 \n",
      "                                                                 \n",
      " reshape_4 (Reshape)         (None, 128, 1)            0         \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirectio  (None, 128, 64)          8704      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_9 (Bidirectio  (None, 32)               10368     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 128)               4224      \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 13)                845       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 124,675,085\n",
      "Trainable params: 124,675,085\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_LTSM = tf.keras.Sequential()\n",
    "\n",
    "model_LTSM.add(hub_layer)\n",
    "\n",
    "model_LTSM.add(tf.keras.layers.Reshape( target_shape=(128 , 1 ) ))\n",
    "\n",
    "model_LTSM.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)))\n",
    "\n",
    "model_LTSM.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)))\n",
    "\n",
    "for units in [128, 64 ]:\n",
    "\n",
    "  model_LTSM.add(tf.keras.layers.Dense(units, activation='relu'))\n",
    "\n",
    "  model_LTSM.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model_LTSM.add(tf.keras.layers.Dense(13, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "model_LTSM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam',\n",
    "loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_f = train_data_f.shuffle(70000).batch(512)\n",
    "test_data_f = test_data_f.batch(512)\n",
    "val_data_f = val_data_f.batch(512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ifeol\\anaconda3.1\\envs\\DevEnv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 29s 1s/step - loss: 2.8913 - accuracy: 0.3060 - val_loss: 2.1458 - val_accuracy: 0.3273\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 24s 1s/step - loss: 2.3360 - accuracy: 0.3238 - val_loss: 1.8890 - val_accuracy: 0.3273\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 24s 1s/step - loss: 2.0328 - accuracy: 0.3243 - val_loss: 1.6147 - val_accuracy: 0.3273\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 23s 1s/step - loss: 1.5912 - accuracy: 0.3474 - val_loss: 1.4229 - val_accuracy: 0.4034\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 23s 1s/step - loss: 1.2906 - accuracy: 0.4186 - val_loss: 1.3725 - val_accuracy: 0.4182\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 24s 1s/step - loss: 1.1262 - accuracy: 0.4479 - val_loss: 1.3614 - val_accuracy: 0.4216\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 24s 1s/step - loss: 1.0128 - accuracy: 0.4520 - val_loss: 1.2776 - val_accuracy: 0.4180\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 23s 1s/step - loss: 0.9098 - accuracy: 0.4523 - val_loss: 1.2882 - val_accuracy: 0.4278\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 24s 1s/step - loss: 0.7974 - accuracy: 0.4590 - val_loss: 1.3054 - val_accuracy: 0.4340\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 23s 1s/step - loss: 0.7190 - accuracy: 0.5233 - val_loss: 1.2288 - val_accuracy: 0.5629\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 27s 1s/step - loss: 0.6307 - accuracy: 0.6572 - val_loss: 1.3119 - val_accuracy: 0.6248\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 31s 1s/step - loss: 0.5429 - accuracy: 0.7341 - val_loss: 1.1949 - val_accuracy: 0.6874\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 31s 1s/step - loss: 0.4566 - accuracy: 0.7792 - val_loss: 1.2142 - val_accuracy: 0.7038\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 30s 1s/step - loss: 0.4088 - accuracy: 0.8116 - val_loss: 1.2428 - val_accuracy: 0.7120\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 28s 1s/step - loss: 0.3551 - accuracy: 0.8377 - val_loss: 1.3389 - val_accuracy: 0.7096\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 29s 1s/step - loss: 0.3177 - accuracy: 0.8563 - val_loss: 1.3817 - val_accuracy: 0.7215\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 31s 1s/step - loss: 0.2866 - accuracy: 0.8718 - val_loss: 1.3746 - val_accuracy: 0.7249\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 31s 1s/step - loss: 0.2627 - accuracy: 0.8872 - val_loss: 1.4107 - val_accuracy: 0.7391\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 30s 1s/step - loss: 0.2203 - accuracy: 0.9041 - val_loss: 1.4326 - val_accuracy: 0.7413\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 31s 1s/step - loss: 0.2000 - accuracy: 0.9105 - val_loss: 1.4094 - val_accuracy: 0.7431\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 30s 1s/step - loss: 0.1830 - accuracy: 0.9216 - val_loss: 1.4918 - val_accuracy: 0.7417\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 30s 1s/step - loss: 0.1707 - accuracy: 0.9315 - val_loss: 1.5737 - val_accuracy: 0.7495\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 27s 1s/step - loss: 0.1853 - accuracy: 0.9328 - val_loss: 1.4875 - val_accuracy: 0.7457\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 26s 1s/step - loss: 0.1594 - accuracy: 0.9443 - val_loss: 1.5288 - val_accuracy: 0.7515\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 26s 1s/step - loss: 0.1342 - accuracy: 0.9498 - val_loss: 1.6286 - val_accuracy: 0.7557\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 26s 1s/step - loss: 0.1222 - accuracy: 0.9572 - val_loss: 1.6645 - val_accuracy: 0.7613\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 26s 1s/step - loss: 0.1094 - accuracy: 0.9639 - val_loss: 1.7197 - val_accuracy: 0.7653\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 26s 1s/step - loss: 0.0888 - accuracy: 0.9704 - val_loss: 1.7353 - val_accuracy: 0.7650\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 26s 1s/step - loss: 0.0791 - accuracy: 0.9735 - val_loss: 1.8462 - val_accuracy: 0.7648\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 26s 1s/step - loss: 0.0714 - accuracy: 0.9750 - val_loss: 1.8350 - val_accuracy: 0.7748\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data_f,\n",
    "                    epochs=30,\n",
    "                    validation_data = val_data_f,\n",
    "                    verbose = 1,\n",
    "                    class_weight = weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ifeol\\OneDrive\\Documents\\Projects\\Emotion-app\\Notebooks\\keras.ipynb Cell 31'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ifeol/OneDrive/Documents/Projects/Emotion-app/Notebooks/keras.ipynb#ch0000030?line=0'>1</a>\u001b[0m test_batch \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(dataset_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ifeol/OneDrive/Documents/Projects/Emotion-app/Notebooks/keras.ipynb#ch0000030?line=2'>3</a>\u001b[0m results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(dataset_test\u001b[39m.\u001b[39mmap(fetch)\u001b[39m.\u001b[39mbatch(test_batch), verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ifeol/OneDrive/Documents/Projects/Emotion-app/Notebooks/keras.ipynb#ch0000030?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(results)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset_test' is not defined"
     ]
    }
   ],
   "source": [
    "test_batch = len(dataset_test)\n",
    "\n",
    "results = model.evaluate(dataset_test.map(fetch).batch(test_batch), verbose=2)\n",
    "print(results)\n",
    "test_data, test_labels = next(iter(dataset_test.map(fetch).batch(45963)))\n",
    "y_pred = model.predict(test_data)\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1845\n",
      "           1       0.76      0.69      0.73       921\n",
      "           2       0.64      0.60      0.62       518\n",
      "           3       0.46      0.49      0.48       264\n",
      "           4       0.69      0.74      0.71       753\n",
      "           5       0.85      0.87      0.86      2137\n",
      "\n",
      "    accuracy                           0.78      6438\n",
      "   macro avg       0.70      0.70      0.70      6438\n",
      "weighted avg       0.78      0.78      0.78      6438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels.numpy().argmax(axis=1), y_pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='sentiment', ylabel='count'>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='sentiment', data=dataset_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset_2, test_size= 0.3, random_state=111)\n",
    "train, val = train_test_split(train, test_size=0.3, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2['content'] = dataset_2['content'].apply(lambda x: preprocess_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>tiffanylue know was listenin to bad habit ear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>layin bed with headache ughhhh waitin on your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>funeral ceremony gloomy friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>dannycastillo we want to trade with someone w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>1753918954</td>\n",
       "      <td>neutral</td>\n",
       "      <td>showMe_Heaven</td>\n",
       "      <td>johnlloydtaylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>1753919001</td>\n",
       "      <td>love</td>\n",
       "      <td>drapeaux</td>\n",
       "      <td>happy mothers day all my love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>1753919005</td>\n",
       "      <td>love</td>\n",
       "      <td>JenniRox</td>\n",
       "      <td>happy mother day to all the mommies out there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>1753919043</td>\n",
       "      <td>happiness</td>\n",
       "      <td>ipdaman1</td>\n",
       "      <td>niariley wassup beautiful follow me peep out ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>1753919049</td>\n",
       "      <td>love</td>\n",
       "      <td>Alpharalpha</td>\n",
       "      <td>mopedronin bullet train from tokyo the gf and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id   sentiment         author  \\\n",
       "0      1956967341       empty     xoshayzers   \n",
       "1      1956967666     sadness      wannamama   \n",
       "2      1956967696     sadness      coolfunky   \n",
       "3      1956967789  enthusiasm    czareaquino   \n",
       "4      1956968416     neutral      xkilljoyx   \n",
       "...           ...         ...            ...   \n",
       "39995  1753918954     neutral  showMe_Heaven   \n",
       "39996  1753919001        love       drapeaux   \n",
       "39997  1753919005        love       JenniRox   \n",
       "39998  1753919043   happiness       ipdaman1   \n",
       "39999  1753919049        love    Alpharalpha   \n",
       "\n",
       "                                                 content  \n",
       "0       tiffanylue know was listenin to bad habit ear...  \n",
       "1      layin bed with headache ughhhh waitin on your ...  \n",
       "2                        funeral ceremony gloomy friday   \n",
       "3                   wants to hang out with friends soon   \n",
       "4       dannycastillo we want to trade with someone w...  \n",
       "...                                                  ...  \n",
       "39995                                    johnlloydtaylor  \n",
       "39996                      happy mothers day all my love  \n",
       "39997  happy mother day to all the mommies out there ...  \n",
       "39998   niariley wassup beautiful follow me peep out ...  \n",
       "39999   mopedronin bullet train from tokyo the gf and...  \n",
       "\n",
       "[40000 rows x 4 columns]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.content\n",
    "X_test = test.content\n",
    "X_val = val.content\n",
    "\n",
    "y_train = train.sentiment\n",
    "y_test = test.sentiment\n",
    "y_val = val.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = list(class_weight.compute_class_weight(\n",
    "    class_weight = 'balanced', \n",
    "    classes = np.unique(dataset_2['sentiment']), \n",
    "    y = dataset_2['sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['empty', 'sadness', 'enthusiasm', 'neutral', 'worry', 'surprise',\n",
       "       'love', 'fun', 'hate', 'happiness', 'boredom', 'relief', 'anger'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_2.sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3562078116373092,\n",
       " 0.3637454872825484,\n",
       " 0.5906936219856166,\n",
       " 0.5957256683297342,\n",
       " 0.8008649341288592,\n",
       " 1.4069149871619007,\n",
       " 1.7325017325017324,\n",
       " 2.0163322915616493,\n",
       " 2.3257166114308974,\n",
       " 3.7205841317086783,\n",
       " 4.053917097395359,\n",
       " 17.189514396218307,\n",
       " 27.972027972027973]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {}\n",
    "\n",
    "for index, weight in enumerate(class_weights):\n",
    "    weights[index] = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = tf.data.Dataset.from_tensor_slices((train['content'].values, train['sentiment'].values))\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((test['content'].values, test['sentiment'].values))\n",
    "dataset_val = tf.data.Dataset.from_tensor_slices((val['content'].values, val['sentiment'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: b'Is getting ready for work... Working all weekend', Emotion: b'neutral'\n",
      "Text: b\"@happy_pills we have a punching bag here! but ive never touched it, covered with my brother's sweat.. but u can use it if u want! hehe\", Emotion: b'happiness'\n",
      "Text: b'@Mollieandme When oh when are you coming back for a gig in Scotland? I had tickets to see u last year but was in hosp wit gallstones!', Emotion: b'neutral'\n",
      "Text: b\"@purpleshoe Ahh! normally I would jump at that but i'm manning the office solo today\", Emotion: b'worry'\n",
      "Text: b\"Here's @Euan and @stoweboyd at our evening drink on Thursday night in London.  http://twitpic.com/4wrrp\", Emotion: b'happiness'\n",
      "Text: b'Memorizing the first 18 lines of the General Prologue of The Canterbury Tales. Ughhh.', Emotion: b'worry'\n",
      "Text: b'So tired. Work today.', Emotion: b'worry'\n"
     ]
    }
   ],
   "source": [
    "for text, target in dataset_train.take(7\n",
    "):\n",
    "    print(f'Text: {text}, Emotion: {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = tf.lookup.StaticHashTable(\n",
    "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
    "        keys=tf.constant(['empty', 'sadness', 'enthusiasm', 'neutral', 'worry', 'surprise','love', 'fun', 'hate', 'happiness', 'boredom', 'relief', 'anger']),\n",
    "        values=tf.constant([0,1,2,3,4,5,6,7,8,9,10,11,12]),\n",
    "    ),\n",
    "    default_value=tf.constant(-1),\n",
    "    name = \"target_encoding\"\n",
    ")\n",
    "\n",
    "@tf.function\n",
    "def target(x):\n",
    "    return table.lookup(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(dataset, size=5):\n",
    "    for batch, label in dataset.take(size):\n",
    "        print(batch.numpy())\n",
    "        print(target(label).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'... I will launch (make or break) the alpha phase of my residential real estate rental website. (Commitment of first grade'\n",
      "4\n",
      "b\"@hughsbeautiful Oherr it's soon then, do you have plans? I had a party on saturday  x\"\n",
      "3\n",
      "b'This thunder is scaring the hell out of me...geez...I HATE THUNDER  we better not loose electricity... #fb http://myloc.me/2144'\n",
      "5\n",
      "b'@Streyeder You rock my socks off! Sorry you have to go to BFE Maryland.'\n",
      "3\n",
      "b\"@orbitaldiamonds I want all the soldiers to come home so we don't have to hear about anymore being killed.\"\n",
      "4\n",
      "b\"Nic has no idea what he's going to do!  money is all gone!\"\n",
      "4\n",
      "b'massive headache  going to see terminator tonight!'\n",
      "9\n",
      "b'I really want to be a star...Hope Flawless will work'\n",
      "9\n",
      "b'sees your Steve Coogan and raises you a Dylan Moran.'\n",
      "3\n",
      "b'@DChi606 Sadly, all I have is the Stanley Steemer 800 number.'\n",
      "3\n",
      "b'@jojototh @abduzeedo firefox ok, but opera and IE - footer is not ok'\n",
      "8\n",
      "b\"Happy Mother's Day one day early to all moms everywhere---you deserve to have your own day.\"\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "show_batch(dataset_test, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch(text, labels):\n",
    "    return text, tf.one_hot(target(labels), 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_f = dataset_train.map(fetch)\n",
    "test_data_f = dataset_test.map(fetch)\n",
    "val_data_f = dataset_val.map(fetch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=string, numpy=b'Is getting ready for work... Working all weekend'>,\n",
       " <tf.Tensor: shape=(13,), dtype=float32, numpy=array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_data_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(5,), dtype=string, numpy=\n",
       " array([b'Is getting ready for work... Working all weekend',\n",
       "        b\"@happy_pills we have a punching bag here! but ive never touched it, covered with my brother's sweat.. but u can use it if u want! hehe\",\n",
       "        b'@Mollieandme When oh when are you coming back for a gig in Scotland? I had tickets to see u last year but was in hosp wit gallstones!',\n",
       "        b\"@purpleshoe Ahh! normally I would jump at that but i'm manning the office solo today\",\n",
       "        b\"Here's @Euan and @stoweboyd at our evening drink on Thursday night in London.  http://twitpic.com/4wrrp\"],\n",
       "       dtype=object)>,\n",
       " <tf.Tensor: shape=(5, 13), dtype=float32, numpy=\n",
       " array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, train_labels = next(iter(train_data_f.batch(5)))\n",
    "train_data, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LTSM.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.7), \n",
    "        loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_f = train_data_f.shuffle(70000).batch(512)\n",
    "test_data_f = test_data_f.batch(512)\n",
    "val_data_f = val_data_f.batch(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "39/39 [==============================] - 57s 1s/step - loss: 0.8485 - accuracy: 0.6334 - val_loss: 6.6225 - val_accuracy: 0.2164\n",
      "Epoch 2/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.8478 - accuracy: 0.6323 - val_loss: 6.3248 - val_accuracy: 0.2186\n",
      "Epoch 3/200\n",
      "39/39 [==============================] - 56s 1s/step - loss: 0.8276 - accuracy: 0.6402 - val_loss: 6.7996 - val_accuracy: 0.2152\n",
      "Epoch 4/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.8174 - accuracy: 0.6412 - val_loss: 6.8972 - val_accuracy: 0.2170\n",
      "Epoch 5/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.7996 - accuracy: 0.6456 - val_loss: 6.8107 - val_accuracy: 0.2205\n",
      "Epoch 6/200\n",
      "39/39 [==============================] - 55s 1s/step - loss: 0.8337 - accuracy: 0.6374 - val_loss: 6.7859 - val_accuracy: 0.2173\n",
      "Epoch 7/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.8059 - accuracy: 0.6518 - val_loss: 6.9447 - val_accuracy: 0.2155\n",
      "Epoch 8/200\n",
      "39/39 [==============================] - 55s 1s/step - loss: 0.8113 - accuracy: 0.6463 - val_loss: 6.7261 - val_accuracy: 0.2199\n",
      "Epoch 9/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.8318 - accuracy: 0.6465 - val_loss: 6.7551 - val_accuracy: 0.2212\n",
      "Epoch 10/200\n",
      "39/39 [==============================] - 52s 1s/step - loss: 0.8511 - accuracy: 0.6404 - val_loss: 7.1524 - val_accuracy: 0.2154\n",
      "Epoch 11/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.7861 - accuracy: 0.6521 - val_loss: 6.9646 - val_accuracy: 0.2145\n",
      "Epoch 12/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.7931 - accuracy: 0.6522 - val_loss: 7.5273 - val_accuracy: 0.2123\n",
      "Epoch 13/200\n",
      "39/39 [==============================] - 59s 1s/step - loss: 0.7855 - accuracy: 0.6586 - val_loss: 6.9795 - val_accuracy: 0.2127\n",
      "Epoch 14/200\n",
      "39/39 [==============================] - 55s 1s/step - loss: 0.7597 - accuracy: 0.6618 - val_loss: 7.2674 - val_accuracy: 0.2232\n",
      "Epoch 15/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.8102 - accuracy: 0.6495 - val_loss: 7.2978 - val_accuracy: 0.2227\n",
      "Epoch 16/200\n",
      "39/39 [==============================] - 57s 1s/step - loss: 0.7965 - accuracy: 0.6541 - val_loss: 7.3216 - val_accuracy: 0.2192\n",
      "Epoch 17/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.8346 - accuracy: 0.6435 - val_loss: 6.3475 - val_accuracy: 0.2177\n",
      "Epoch 18/200\n",
      "39/39 [==============================] - 52s 1s/step - loss: 0.8657 - accuracy: 0.6346 - val_loss: 7.1195 - val_accuracy: 0.2195\n",
      "Epoch 19/200\n",
      "39/39 [==============================] - 49s 1s/step - loss: 0.8289 - accuracy: 0.6412 - val_loss: 7.2844 - val_accuracy: 0.2113\n",
      "Epoch 20/200\n",
      "39/39 [==============================] - 55s 1s/step - loss: 0.8926 - accuracy: 0.6294 - val_loss: 7.2576 - val_accuracy: 0.2169\n",
      "Epoch 21/200\n",
      "39/39 [==============================] - 55s 1s/step - loss: 0.7822 - accuracy: 0.6570 - val_loss: 7.4342 - val_accuracy: 0.2157\n",
      "Epoch 22/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.7730 - accuracy: 0.6596 - val_loss: 7.4298 - val_accuracy: 0.2165\n",
      "Epoch 23/200\n",
      "39/39 [==============================] - 55s 1s/step - loss: 0.7565 - accuracy: 0.6634 - val_loss: 7.4751 - val_accuracy: 0.2175\n",
      "Epoch 24/200\n",
      "39/39 [==============================] - 55s 1s/step - loss: 0.9172 - accuracy: 0.6255 - val_loss: 6.9326 - val_accuracy: 0.2114\n",
      "Epoch 25/200\n",
      "39/39 [==============================] - 56s 1s/step - loss: 0.8400 - accuracy: 0.6547 - val_loss: 7.0495 - val_accuracy: 0.2129\n",
      "Epoch 26/200\n",
      "39/39 [==============================] - 56s 1s/step - loss: 0.7995 - accuracy: 0.6603 - val_loss: 6.9569 - val_accuracy: 0.2211\n",
      "Epoch 27/200\n",
      "39/39 [==============================] - 56s 1s/step - loss: 0.7429 - accuracy: 0.6678 - val_loss: 7.6584 - val_accuracy: 0.2182\n",
      "Epoch 28/200\n",
      "39/39 [==============================] - 55s 1s/step - loss: 0.7458 - accuracy: 0.6656 - val_loss: 7.7433 - val_accuracy: 0.2231\n",
      "Epoch 29/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.6932 - accuracy: 0.6780 - val_loss: 8.0733 - val_accuracy: 0.2199\n",
      "Epoch 30/200\n",
      "39/39 [==============================] - 56s 1s/step - loss: 0.7397 - accuracy: 0.6637 - val_loss: 7.6610 - val_accuracy: 0.2157\n",
      "Epoch 31/200\n",
      "39/39 [==============================] - 55s 1s/step - loss: 0.7307 - accuracy: 0.6748 - val_loss: 7.8564 - val_accuracy: 0.2210\n",
      "Epoch 32/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.6896 - accuracy: 0.6874 - val_loss: 8.0485 - val_accuracy: 0.2194\n",
      "Epoch 33/200\n",
      "39/39 [==============================] - 55s 1s/step - loss: 0.7055 - accuracy: 0.6759 - val_loss: 7.7239 - val_accuracy: 0.2126\n",
      "Epoch 34/200\n",
      "39/39 [==============================] - 55s 1s/step - loss: 0.7085 - accuracy: 0.6752 - val_loss: 8.2605 - val_accuracy: 0.2138\n",
      "Epoch 35/200\n",
      "39/39 [==============================] - 56s 1s/step - loss: 0.6508 - accuracy: 0.6916 - val_loss: 8.4662 - val_accuracy: 0.2160\n",
      "Epoch 36/200\n",
      "39/39 [==============================] - 55s 1s/step - loss: 0.6347 - accuracy: 0.6943 - val_loss: 8.5760 - val_accuracy: 0.2149\n",
      "Epoch 37/200\n",
      "39/39 [==============================] - 57s 1s/step - loss: 0.6981 - accuracy: 0.6840 - val_loss: 8.0870 - val_accuracy: 0.2156\n",
      "Epoch 38/200\n",
      "39/39 [==============================] - 55s 1s/step - loss: 0.6938 - accuracy: 0.6874 - val_loss: 8.5164 - val_accuracy: 0.2164\n",
      "Epoch 39/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.6484 - accuracy: 0.6920 - val_loss: 8.6564 - val_accuracy: 0.2206\n",
      "Epoch 40/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.6437 - accuracy: 0.6986 - val_loss: 9.1892 - val_accuracy: 0.2148\n",
      "Epoch 41/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.6485 - accuracy: 0.6960 - val_loss: 8.8505 - val_accuracy: 0.2138\n",
      "Epoch 42/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.6628 - accuracy: 0.6948 - val_loss: 8.8009 - val_accuracy: 0.2199\n",
      "Epoch 43/200\n",
      "39/39 [==============================] - 56s 1s/step - loss: 0.6177 - accuracy: 0.7053 - val_loss: 8.8790 - val_accuracy: 0.2121\n",
      "Epoch 44/200\n",
      "39/39 [==============================] - 52s 1s/step - loss: 0.6185 - accuracy: 0.7046 - val_loss: 9.0089 - val_accuracy: 0.2179\n",
      "Epoch 45/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.6754 - accuracy: 0.6932 - val_loss: 8.6846 - val_accuracy: 0.2196\n",
      "Epoch 46/200\n",
      "39/39 [==============================] - 55s 1s/step - loss: 0.6425 - accuracy: 0.6967 - val_loss: 8.9300 - val_accuracy: 0.2194\n",
      "Epoch 47/200\n",
      "39/39 [==============================] - 56s 1s/step - loss: 0.6300 - accuracy: 0.7027 - val_loss: 9.3110 - val_accuracy: 0.2179\n",
      "Epoch 48/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.6662 - accuracy: 0.6953 - val_loss: 9.3524 - val_accuracy: 0.2182\n",
      "Epoch 49/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.6120 - accuracy: 0.6997 - val_loss: 9.0805 - val_accuracy: 0.2124\n",
      "Epoch 50/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.6198 - accuracy: 0.7057 - val_loss: 9.4378 - val_accuracy: 0.2146\n",
      "Epoch 51/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.5938 - accuracy: 0.7080 - val_loss: 9.5831 - val_accuracy: 0.2115\n",
      "Epoch 52/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.5750 - accuracy: 0.7113 - val_loss: 10.0490 - val_accuracy: 0.2215\n",
      "Epoch 53/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.5962 - accuracy: 0.7107 - val_loss: 9.3830 - val_accuracy: 0.2162\n",
      "Epoch 54/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.5900 - accuracy: 0.7087 - val_loss: 9.8497 - val_accuracy: 0.2188\n",
      "Epoch 55/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.5994 - accuracy: 0.7059 - val_loss: 9.8922 - val_accuracy: 0.2157\n",
      "Epoch 56/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.5610 - accuracy: 0.7158 - val_loss: 10.4899 - val_accuracy: 0.2181\n",
      "Epoch 57/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.6177 - accuracy: 0.7039 - val_loss: 9.7613 - val_accuracy: 0.2135\n",
      "Epoch 58/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.5797 - accuracy: 0.7160 - val_loss: 10.3482 - val_accuracy: 0.2151\n",
      "Epoch 59/200\n",
      "39/39 [==============================] - 55s 1s/step - loss: 0.5684 - accuracy: 0.7106 - val_loss: 11.0094 - val_accuracy: 0.2162\n",
      "Epoch 60/200\n",
      "39/39 [==============================] - 56s 1s/step - loss: 0.5673 - accuracy: 0.7127 - val_loss: 10.4487 - val_accuracy: 0.2217\n",
      "Epoch 61/200\n",
      "39/39 [==============================] - 55s 1s/step - loss: 0.5902 - accuracy: 0.7081 - val_loss: 10.3960 - val_accuracy: 0.2140\n",
      "Epoch 62/200\n",
      "39/39 [==============================] - 55s 1s/step - loss: 0.5660 - accuracy: 0.7138 - val_loss: 10.2569 - val_accuracy: 0.2189\n",
      "Epoch 63/200\n",
      "39/39 [==============================] - 60s 2s/step - loss: 0.5580 - accuracy: 0.7184 - val_loss: 10.5314 - val_accuracy: 0.2140\n",
      "Epoch 64/200\n",
      "39/39 [==============================] - 56s 1s/step - loss: 0.5613 - accuracy: 0.7156 - val_loss: 10.1681 - val_accuracy: 0.2210\n",
      "Epoch 65/200\n",
      "39/39 [==============================] - 58s 1s/step - loss: 0.5442 - accuracy: 0.7240 - val_loss: 11.4690 - val_accuracy: 0.2154\n",
      "Epoch 66/200\n",
      "39/39 [==============================] - 55s 1s/step - loss: 0.5131 - accuracy: 0.7269 - val_loss: 11.5586 - val_accuracy: 0.2151\n",
      "Epoch 67/200\n",
      "39/39 [==============================] - 57s 1s/step - loss: 0.5746 - accuracy: 0.7123 - val_loss: 10.6048 - val_accuracy: 0.2169\n",
      "Epoch 68/200\n",
      "39/39 [==============================] - 57s 1s/step - loss: 0.5243 - accuracy: 0.7177 - val_loss: 11.1314 - val_accuracy: 0.2199\n",
      "Epoch 69/200\n",
      "39/39 [==============================] - 55s 1s/step - loss: 0.5085 - accuracy: 0.7327 - val_loss: 11.5925 - val_accuracy: 0.2183\n",
      "Epoch 70/200\n",
      "39/39 [==============================] - 56s 1s/step - loss: 0.5312 - accuracy: 0.7255 - val_loss: 10.9174 - val_accuracy: 0.2136\n",
      "Epoch 71/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.5625 - accuracy: 0.7199 - val_loss: 11.5596 - val_accuracy: 0.2158\n",
      "Epoch 72/200\n",
      "39/39 [==============================] - 56s 1s/step - loss: 0.5781 - accuracy: 0.7140 - val_loss: 10.3078 - val_accuracy: 0.2204\n",
      "Epoch 73/200\n",
      "39/39 [==============================] - 55s 1s/step - loss: 0.5985 - accuracy: 0.7091 - val_loss: 10.3532 - val_accuracy: 0.2208\n",
      "Epoch 74/200\n",
      "39/39 [==============================] - 59s 1s/step - loss: 0.5678 - accuracy: 0.7052 - val_loss: 11.1181 - val_accuracy: 0.2160\n",
      "Epoch 75/200\n",
      "39/39 [==============================] - 60s 2s/step - loss: 0.6021 - accuracy: 0.7018 - val_loss: 9.7545 - val_accuracy: 0.2119\n",
      "Epoch 76/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.6009 - accuracy: 0.7065 - val_loss: 10.6386 - val_accuracy: 0.2017\n",
      "Epoch 77/200\n",
      "39/39 [==============================] - 57s 1s/step - loss: 0.5844 - accuracy: 0.7132 - val_loss: 10.8282 - val_accuracy: 0.2179\n",
      "Epoch 78/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.4713 - accuracy: 0.7347 - val_loss: 12.1883 - val_accuracy: 0.2189\n",
      "Epoch 79/200\n",
      "39/39 [==============================] - 57s 1s/step - loss: 0.4919 - accuracy: 0.7333 - val_loss: 11.8696 - val_accuracy: 0.2175\n",
      "Epoch 80/200\n",
      "39/39 [==============================] - 56s 1s/step - loss: 0.5225 - accuracy: 0.7258 - val_loss: 11.7980 - val_accuracy: 0.2243\n",
      "Epoch 81/200\n",
      "39/39 [==============================] - 56s 1s/step - loss: 0.5201 - accuracy: 0.7276 - val_loss: 11.1278 - val_accuracy: 0.2208\n",
      "Epoch 82/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.5458 - accuracy: 0.7277 - val_loss: 11.6533 - val_accuracy: 0.2076\n",
      "Epoch 83/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.6040 - accuracy: 0.7106 - val_loss: 11.0301 - val_accuracy: 0.2046\n",
      "Epoch 84/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.5181 - accuracy: 0.7318 - val_loss: 10.9693 - val_accuracy: 0.2120\n",
      "Epoch 85/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.5220 - accuracy: 0.7326 - val_loss: 11.6315 - val_accuracy: 0.2136\n",
      "Epoch 86/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4750 - accuracy: 0.7402 - val_loss: 11.7116 - val_accuracy: 0.2167\n",
      "Epoch 87/200\n",
      "39/39 [==============================] - 55s 1s/step - loss: 0.4597 - accuracy: 0.7492 - val_loss: 11.7140 - val_accuracy: 0.2179\n",
      "Epoch 88/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.5000 - accuracy: 0.7336 - val_loss: 11.8743 - val_accuracy: 0.2225\n",
      "Epoch 89/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.4526 - accuracy: 0.7485 - val_loss: 12.7095 - val_accuracy: 0.2138\n",
      "Epoch 90/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4916 - accuracy: 0.7512 - val_loss: 11.7571 - val_accuracy: 0.2132\n",
      "Epoch 91/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.4727 - accuracy: 0.7376 - val_loss: 12.3019 - val_accuracy: 0.2177\n",
      "Epoch 92/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4585 - accuracy: 0.7469 - val_loss: 12.4296 - val_accuracy: 0.2211\n",
      "Epoch 93/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.5015 - accuracy: 0.7390 - val_loss: 12.1553 - val_accuracy: 0.2150\n",
      "Epoch 94/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4738 - accuracy: 0.7402 - val_loss: 12.1022 - val_accuracy: 0.2082\n",
      "Epoch 95/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4612 - accuracy: 0.7461 - val_loss: 12.6456 - val_accuracy: 0.2175\n",
      "Epoch 96/200\n",
      "39/39 [==============================] - 55s 1s/step - loss: 0.5292 - accuracy: 0.7383 - val_loss: 11.8706 - val_accuracy: 0.2139\n",
      "Epoch 97/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.4597 - accuracy: 0.7460 - val_loss: 12.9048 - val_accuracy: 0.2135\n",
      "Epoch 98/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4732 - accuracy: 0.7394 - val_loss: 12.8976 - val_accuracy: 0.2155\n",
      "Epoch 99/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4807 - accuracy: 0.7432 - val_loss: 12.4417 - val_accuracy: 0.2167\n",
      "Epoch 100/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4619 - accuracy: 0.7459 - val_loss: 13.0032 - val_accuracy: 0.2079\n",
      "Epoch 101/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4679 - accuracy: 0.7478 - val_loss: 13.0481 - val_accuracy: 0.2186\n",
      "Epoch 102/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4433 - accuracy: 0.7479 - val_loss: 12.7773 - val_accuracy: 0.2163\n",
      "Epoch 103/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.5360 - accuracy: 0.7374 - val_loss: 12.3621 - val_accuracy: 0.2151\n",
      "Epoch 104/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.7874 - accuracy: 0.6953 - val_loss: 10.0887 - val_accuracy: 0.2133\n",
      "Epoch 105/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.5683 - accuracy: 0.7283 - val_loss: 11.4073 - val_accuracy: 0.2152\n",
      "Epoch 106/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.5339 - accuracy: 0.7377 - val_loss: 11.4781 - val_accuracy: 0.2130\n",
      "Epoch 107/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4613 - accuracy: 0.7539 - val_loss: 11.8377 - val_accuracy: 0.2105\n",
      "Epoch 108/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4574 - accuracy: 0.7579 - val_loss: 11.9010 - val_accuracy: 0.2095\n",
      "Epoch 109/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4182 - accuracy: 0.7643 - val_loss: 12.8296 - val_accuracy: 0.2121\n",
      "Epoch 110/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4137 - accuracy: 0.7745 - val_loss: 12.6676 - val_accuracy: 0.2106\n",
      "Epoch 111/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4378 - accuracy: 0.7675 - val_loss: 12.5569 - val_accuracy: 0.2126\n",
      "Epoch 112/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.5662 - accuracy: 0.7435 - val_loss: 10.9623 - val_accuracy: 0.2149\n",
      "Epoch 113/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.5553 - accuracy: 0.7326 - val_loss: 10.0357 - val_accuracy: 0.2090\n",
      "Epoch 114/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4953 - accuracy: 0.7363 - val_loss: 11.9548 - val_accuracy: 0.2101\n",
      "Epoch 115/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4557 - accuracy: 0.7507 - val_loss: 12.1041 - val_accuracy: 0.2125\n",
      "Epoch 116/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4431 - accuracy: 0.7623 - val_loss: 12.8326 - val_accuracy: 0.2143\n",
      "Epoch 117/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4221 - accuracy: 0.7656 - val_loss: 12.8276 - val_accuracy: 0.2135\n",
      "Epoch 118/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4199 - accuracy: 0.7724 - val_loss: 12.9649 - val_accuracy: 0.2143\n",
      "Epoch 119/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3950 - accuracy: 0.7766 - val_loss: 13.2202 - val_accuracy: 0.2095\n",
      "Epoch 120/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4542 - accuracy: 0.7742 - val_loss: 12.7858 - val_accuracy: 0.2062\n",
      "Epoch 121/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4871 - accuracy: 0.7481 - val_loss: 12.7472 - val_accuracy: 0.2120\n",
      "Epoch 122/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4094 - accuracy: 0.7719 - val_loss: 13.2408 - val_accuracy: 0.2126\n",
      "Epoch 123/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3918 - accuracy: 0.7780 - val_loss: 13.0928 - val_accuracy: 0.2115\n",
      "Epoch 124/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4147 - accuracy: 0.7824 - val_loss: 13.6749 - val_accuracy: 0.2119\n",
      "Epoch 125/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4223 - accuracy: 0.7850 - val_loss: 12.6246 - val_accuracy: 0.2155\n",
      "Epoch 126/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3992 - accuracy: 0.7896 - val_loss: 13.1827 - val_accuracy: 0.2079\n",
      "Epoch 127/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3823 - accuracy: 0.7927 - val_loss: 13.4728 - val_accuracy: 0.2073\n",
      "Epoch 128/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3785 - accuracy: 0.7976 - val_loss: 13.9995 - val_accuracy: 0.2118\n",
      "Epoch 129/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3911 - accuracy: 0.7891 - val_loss: 13.8013 - val_accuracy: 0.2155\n",
      "Epoch 130/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.3669 - accuracy: 0.7965 - val_loss: 14.2116 - val_accuracy: 0.2057\n",
      "Epoch 131/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.3421 - accuracy: 0.8079 - val_loss: 14.4575 - val_accuracy: 0.2120\n",
      "Epoch 132/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3788 - accuracy: 0.8011 - val_loss: 13.7980 - val_accuracy: 0.2098\n",
      "Epoch 133/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3996 - accuracy: 0.7815 - val_loss: 13.8925 - val_accuracy: 0.2036\n",
      "Epoch 134/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3862 - accuracy: 0.7922 - val_loss: 14.2426 - val_accuracy: 0.2036\n",
      "Epoch 135/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3871 - accuracy: 0.8044 - val_loss: 14.2224 - val_accuracy: 0.2067\n",
      "Epoch 136/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.3963 - accuracy: 0.7938 - val_loss: 13.9505 - val_accuracy: 0.2117\n",
      "Epoch 137/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4031 - accuracy: 0.7969 - val_loss: 13.2791 - val_accuracy: 0.2014\n",
      "Epoch 138/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3658 - accuracy: 0.8063 - val_loss: 14.0795 - val_accuracy: 0.2071\n",
      "Epoch 139/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3538 - accuracy: 0.8169 - val_loss: 14.1297 - val_accuracy: 0.1949\n",
      "Epoch 140/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.5119 - accuracy: 0.7754 - val_loss: 12.8749 - val_accuracy: 0.2048\n",
      "Epoch 141/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4667 - accuracy: 0.7733 - val_loss: 12.7980 - val_accuracy: 0.2080\n",
      "Epoch 142/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4511 - accuracy: 0.7773 - val_loss: 12.5054 - val_accuracy: 0.2011\n",
      "Epoch 143/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4602 - accuracy: 0.7858 - val_loss: 13.3872 - val_accuracy: 0.2032\n",
      "Epoch 144/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4190 - accuracy: 0.7907 - val_loss: 12.9198 - val_accuracy: 0.2064\n",
      "Epoch 145/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4116 - accuracy: 0.7898 - val_loss: 14.4831 - val_accuracy: 0.2013\n",
      "Epoch 146/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4509 - accuracy: 0.7874 - val_loss: 13.5401 - val_accuracy: 0.2002\n",
      "Epoch 147/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4484 - accuracy: 0.7831 - val_loss: 13.0139 - val_accuracy: 0.2142\n",
      "Epoch 148/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.4192 - accuracy: 0.7909 - val_loss: 13.2221 - val_accuracy: 0.2089\n",
      "Epoch 149/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4539 - accuracy: 0.7910 - val_loss: 12.3753 - val_accuracy: 0.2049\n",
      "Epoch 150/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4226 - accuracy: 0.7943 - val_loss: 13.6496 - val_accuracy: 0.2008\n",
      "Epoch 151/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3948 - accuracy: 0.8104 - val_loss: 13.7669 - val_accuracy: 0.2051\n",
      "Epoch 152/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3590 - accuracy: 0.8169 - val_loss: 13.9894 - val_accuracy: 0.2049\n",
      "Epoch 153/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3548 - accuracy: 0.8238 - val_loss: 14.2024 - val_accuracy: 0.2008\n",
      "Epoch 154/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3403 - accuracy: 0.8302 - val_loss: 14.5582 - val_accuracy: 0.2093\n",
      "Epoch 155/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3509 - accuracy: 0.8249 - val_loss: 14.5295 - val_accuracy: 0.2064\n",
      "Epoch 156/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3619 - accuracy: 0.8257 - val_loss: 14.3479 - val_accuracy: 0.2073\n",
      "Epoch 157/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3362 - accuracy: 0.8267 - val_loss: 15.2591 - val_accuracy: 0.2045\n",
      "Epoch 158/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3594 - accuracy: 0.8199 - val_loss: 14.1161 - val_accuracy: 0.2069\n",
      "Epoch 159/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3365 - accuracy: 0.8284 - val_loss: 14.7513 - val_accuracy: 0.2101\n",
      "Epoch 160/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3420 - accuracy: 0.8236 - val_loss: 15.0511 - val_accuracy: 0.2010\n",
      "Epoch 161/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3383 - accuracy: 0.8333 - val_loss: 15.1305 - val_accuracy: 0.2077\n",
      "Epoch 162/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3334 - accuracy: 0.8367 - val_loss: 15.9525 - val_accuracy: 0.2101\n",
      "Epoch 163/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3700 - accuracy: 0.8232 - val_loss: 14.5637 - val_accuracy: 0.2051\n",
      "Epoch 164/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3434 - accuracy: 0.8305 - val_loss: 15.4621 - val_accuracy: 0.2048\n",
      "Epoch 165/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.3356 - accuracy: 0.8382 - val_loss: 15.6377 - val_accuracy: 0.2111\n",
      "Epoch 166/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3243 - accuracy: 0.8410 - val_loss: 16.8914 - val_accuracy: 0.2039\n",
      "Epoch 167/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3823 - accuracy: 0.8314 - val_loss: 13.6870 - val_accuracy: 0.1987\n",
      "Epoch 168/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3960 - accuracy: 0.8254 - val_loss: 14.9779 - val_accuracy: 0.1999\n",
      "Epoch 169/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3484 - accuracy: 0.8325 - val_loss: 14.2857 - val_accuracy: 0.2029\n",
      "Epoch 170/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3193 - accuracy: 0.8407 - val_loss: 15.1659 - val_accuracy: 0.2045\n",
      "Epoch 171/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3143 - accuracy: 0.8476 - val_loss: 15.6987 - val_accuracy: 0.2056\n",
      "Epoch 172/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.2963 - accuracy: 0.8551 - val_loss: 15.0579 - val_accuracy: 0.2039\n",
      "Epoch 173/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3328 - accuracy: 0.8424 - val_loss: 15.5826 - val_accuracy: 0.2048\n",
      "Epoch 174/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3437 - accuracy: 0.8435 - val_loss: 15.3209 - val_accuracy: 0.2058\n",
      "Epoch 175/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3340 - accuracy: 0.8389 - val_loss: 15.9417 - val_accuracy: 0.2101\n",
      "Epoch 176/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3249 - accuracy: 0.8424 - val_loss: 16.3824 - val_accuracy: 0.2006\n",
      "Epoch 177/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.2953 - accuracy: 0.8515 - val_loss: 16.2459 - val_accuracy: 0.2125\n",
      "Epoch 178/200\n",
      "39/39 [==============================] - 52s 1s/step - loss: 0.3412 - accuracy: 0.8427 - val_loss: 15.7644 - val_accuracy: 0.2015\n",
      "Epoch 179/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3018 - accuracy: 0.8506 - val_loss: 16.7555 - val_accuracy: 0.2115\n",
      "Epoch 180/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.2925 - accuracy: 0.8545 - val_loss: 16.6260 - val_accuracy: 0.2042\n",
      "Epoch 181/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.2936 - accuracy: 0.8541 - val_loss: 17.2497 - val_accuracy: 0.2077\n",
      "Epoch 182/200\n",
      "39/39 [==============================] - 55s 1s/step - loss: 0.3051 - accuracy: 0.8529 - val_loss: 16.5118 - val_accuracy: 0.2065\n",
      "Epoch 183/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3203 - accuracy: 0.8540 - val_loss: 16.4156 - val_accuracy: 0.2062\n",
      "Epoch 184/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3267 - accuracy: 0.8354 - val_loss: 16.3368 - val_accuracy: 0.1976\n",
      "Epoch 185/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3407 - accuracy: 0.8381 - val_loss: 15.5668 - val_accuracy: 0.2070\n",
      "Epoch 186/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3044 - accuracy: 0.8560 - val_loss: 15.9365 - val_accuracy: 0.2032\n",
      "Epoch 187/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.2652 - accuracy: 0.8649 - val_loss: 16.2807 - val_accuracy: 0.2062\n",
      "Epoch 188/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.2893 - accuracy: 0.8628 - val_loss: 16.7224 - val_accuracy: 0.2057\n",
      "Epoch 189/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3165 - accuracy: 0.8561 - val_loss: 15.5104 - val_accuracy: 0.1974\n",
      "Epoch 190/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3380 - accuracy: 0.8491 - val_loss: 15.3692 - val_accuracy: 0.2044\n",
      "Epoch 191/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3166 - accuracy: 0.8561 - val_loss: 15.8863 - val_accuracy: 0.2036\n",
      "Epoch 192/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.2935 - accuracy: 0.8627 - val_loss: 16.3798 - val_accuracy: 0.2038\n",
      "Epoch 193/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.2787 - accuracy: 0.8708 - val_loss: 16.9521 - val_accuracy: 0.2045\n",
      "Epoch 194/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3136 - accuracy: 0.8578 - val_loss: 16.2469 - val_accuracy: 0.2054\n",
      "Epoch 195/200\n",
      "39/39 [==============================] - 52s 1s/step - loss: 0.3502 - accuracy: 0.8379 - val_loss: 15.5351 - val_accuracy: 0.2069\n",
      "Epoch 196/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3698 - accuracy: 0.8238 - val_loss: 16.4243 - val_accuracy: 0.2033\n",
      "Epoch 197/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.4042 - accuracy: 0.8384 - val_loss: 13.7590 - val_accuracy: 0.2039\n",
      "Epoch 198/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.5153 - accuracy: 0.7839 - val_loss: 14.1908 - val_accuracy: 0.2033\n",
      "Epoch 199/200\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.3945 - accuracy: 0.8195 - val_loss: 14.2687 - val_accuracy: 0.2058\n",
      "Epoch 200/200\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.3668 - accuracy: 0.8360 - val_loss: 14.7752 - val_accuracy: 0.1994\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit(train_data_f,\n",
    "                    epochs=200,\n",
    "                    validation_data = val_data_f,\n",
    "                    verbose = 1,\n",
    "                    class_weight = weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>tiffanylue know was listenin to bad habit ear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin bed with headache ughhhh waitin on your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony gloomy friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>1753918954</td>\n",
       "      <td>neutral</td>\n",
       "      <td>showMe_Heaven</td>\n",
       "      <td>JohnLloydTaylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>1753919001</td>\n",
       "      <td>love</td>\n",
       "      <td>drapeaux</td>\n",
       "      <td>Happy Mothers Day All my love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>1753919005</td>\n",
       "      <td>love</td>\n",
       "      <td>JenniRox</td>\n",
       "      <td>Happy Mother Day to all the mommies out there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>1753919043</td>\n",
       "      <td>happiness</td>\n",
       "      <td>ipdaman1</td>\n",
       "      <td>niariley WASSUP BEAUTIFUL FOLLOW ME PEEP OUT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>1753919049</td>\n",
       "      <td>love</td>\n",
       "      <td>Alpharalpha</td>\n",
       "      <td>mopedronin bullet train from tokyo the gf and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id   sentiment         author  \\\n",
       "0      1956967341       empty     xoshayzers   \n",
       "1      1956967666     sadness      wannamama   \n",
       "2      1956967696     sadness      coolfunky   \n",
       "3      1956967789  enthusiasm    czareaquino   \n",
       "4      1956968416     neutral      xkilljoyx   \n",
       "...           ...         ...            ...   \n",
       "39995  1753918954     neutral  showMe_Heaven   \n",
       "39996  1753919001        love       drapeaux   \n",
       "39997  1753919005        love       JenniRox   \n",
       "39998  1753919043   happiness       ipdaman1   \n",
       "39999  1753919049        love    Alpharalpha   \n",
       "\n",
       "                                                 content  \n",
       "0       tiffanylue know was listenin to bad habit ear...  \n",
       "1      Layin bed with headache ughhhh waitin on your ...  \n",
       "2                        Funeral ceremony gloomy friday   \n",
       "3                   wants to hang out with friends SOON   \n",
       "4       dannycastillo We want to trade with someone w...  \n",
       "...                                                  ...  \n",
       "39995                                    JohnLloydTaylor  \n",
       "39996                      Happy Mothers Day All my love  \n",
       "39997  Happy Mother Day to all the mommies out there ...  \n",
       "39998   niariley WASSUP BEAUTIFUL FOLLOW ME PEEP OUT ...  \n",
       "39999   mopedronin bullet train from tokyo the gf and...  \n",
       "\n",
       "[40000 rows x 4 columns]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 1s - loss: 14.5684 - accuracy: 0.1974 - 870ms/epoch - 870ms/step\n",
      "[14.568422317504883, 0.19741666316986084]\n"
     ]
    }
   ],
   "source": [
    "test_batch = len(dataset_2)\n",
    "\n",
    "results = model2.evaluate(dataset_test.map(fetch).batch(test_batch), verbose=2)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14248\\892334175.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m45963\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\ifeol\\anaconda3.1\\envs\\DevEnv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5485\u001b[0m         ):\n\u001b[0;32m   5486\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5489\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "test_data, test_labels = next(iter(dataset_2.map(fetch).batch(45963)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model2.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels.numpy().argmax(axis=1), y_pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16b930a0b54262db79635409cbb31ff3e7e4e5ab9030b384bcc66de38b7dc4c4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py35')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
